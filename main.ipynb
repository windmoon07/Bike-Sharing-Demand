{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于机器学习模型二次融合的单车使用量回归分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关包\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 数据可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# 模型\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# 杂项\n",
    "import warnings\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置字体为 SimHei（黑体）\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 认识数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/data.csv\", parse_dates=True)  # parse_dates将csv中的时间字符串转换成日期格式\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"数据的形状是{data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      10886 non-null  int64  \n",
      " 1   holiday     10886 non-null  int64  \n",
      " 2   workingday  10886 non-null  int64  \n",
      " 3   weather     10886 non-null  int64  \n",
      " 4   temp        10886 non-null  float64\n",
      " 5   humidity    10886 non-null  int64  \n",
      " 6   windspeed   10886 non-null  float64\n",
      " 7   count       10886 non-null  int64  \n",
      " 8   month       10886 non-null  int32  \n",
      " 9   day         10886 non-null  int32  \n",
      " 10  weekday     10886 non-null  int32  \n",
      " 11  hour        10886 non-null  int32  \n",
      "dtypes: float64(2), int32(4), int64(6)\n",
      "memory usage: 850.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 数据集概览\n",
    "- **数据集大小**: 10,886 行\n",
    "- **列数**: 12 列\n",
    "- **索引范围**: 0 到 10,885\n",
    "\n",
    "### 数据列信息\n",
    "\n",
    "| 列名         | 非空值数量 | 数据类型   | 描述                                                                 |\n",
    "|--------------|------------|------------|----------------------------------------------------------------------|\n",
    "| `datetime`   | 10,886     | `object`   | 日期和时间戳（每小时）                                               |\n",
    "| `season`     | 10,886     | `int64`    | 季节：1 = 春季, 2 = 夏季, 3 = 秋季, 4 = 冬季                          |\n",
    "| `holiday`    | 10,886     | `int64`    | 是否为假日（1 = 是, 0 = 否）                                          |\n",
    "| `workingday` | 10,886     | `int64`    | 是否为工作日（既不是周末也不是假日，1 = 是, 0 = 否）                  |\n",
    "| `weather`    | 10,886     | `int64`    | 天气状况：<br>1: 晴天, 少云, 部分多云<br>2: 雾 + 多云, 雾 + 碎云, 雾 + 少云<br>3: 小雪, 小雨 + 雷阵雨 + 散云, 小雨 + 散云<br>4: 大雨 + 冰雹 + 雷阵雨 + 雾, 雪 + 雾 |\n",
    "| `temp`       | 10,886     | `float64`  | 温度（摄氏度）                                                       |\n",
    "| `atemp`      | 10,886     | `float64`  | 体感温度（摄氏度）                                                   |\n",
    "| `humidity`   | 10,886     | `int64`    | 相对湿度                                                             |\n",
    "| `windspeed`  | 10,886     | `float64`  | 风速                                                                \n",
    "| `count`      | 10,886     | `int64`    | 总租赁次数                                                           |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **内存占用**: 1020.7+ KB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对日期数据进行处理，提取时间相关信息，是一个比较简单的特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日期数据处理\n",
    "format = '%Y-%m-%d %H:%M'  # 调整格式字符串\n",
    "data['date'] = pd.to_datetime(data['datetime'], format=format)\n",
    "data['month'] = data.date.dt.month\n",
    "data['day'] = data.date.dt.day\n",
    "data['weekday'] = data.date.dt.weekday\n",
    "data['hour'] = data.date.dt.hour\n",
    "# 删除不需要的列\n",
    "data.drop(['date'], axis=1, inplace=True)\n",
    "data.drop(['datetime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 描述性统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 观察每个离散特征对于标签的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义离散变量列表\n",
    "discrete_vars = ['season', 'holiday', 'workingday', 'weather', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "# 创建子图布局\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 遍历离散变量并绘制箱线图\n",
    "for i, var in enumerate(discrete_vars):\n",
    "    sns.boxplot(data=data, x=var, y='count', ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of count by {var}')\n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 观察连续特征对于标签的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制原始数据的热力图，查看特征之间的相关性\n",
    "corr_df = data[[\"temp\", \"atemp\", \"humidity\", \"windspeed\", \"count\"]].corr()\n",
    "mask = np.array(corr_df)\n",
    "mask[np.tril_indices_from(mask)] = False  # mask = np.zeros_like(corr) # mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_df, mask=mask, vmax=0.8, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp 和 atemp 之间有很强的相关性，都纳入模型的话会造成多重共线性问题，所以必须删除其中一个特征。我们删除 atemp 特征，因为它与 count之间的相关性较 temp 弱。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['atemp'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离特征数据和标签数据\n",
    "X = data.drop(['count'], axis=1)  # 特征数据\n",
    "y = data['count']  # 标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 y = data['count'] 已经定义\n",
    "# 绘制直方图\n",
    "plt.hist(y, bins=20)  # bins 参数可以调整直方图的柱子数量\n",
    "\n",
    "# 添加标题和坐标轴标签\n",
    "plt.title('Histogram of y')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这里大概一个柱子的数值在0-50左右 最后我们预测的误差可以对比下这个判断多少算多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 train_test_split 函数按照 8:2 的比例划分数据集\n",
    "# test_size=0.2 表示 20%的数据用作测试集，即验证集。\n",
    "# random_state 是一个随机数种子，确保每次划分的结果相同，便于复现结果。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 异常值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 利用箱线图可视化连续特征-湿度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=X_train['humidity'])\n",
    "plt.title(\" humidity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 Q1, Q3 和 IQR\n",
    "Q1 = X_train['humidity'].quantile(0.25)\n",
    "Q3 = X_train['humidity'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 定义异常值的上下界\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# 删除异常值\n",
    "mask = (X_train['humidity'] >= lower_bound) & (X_train['humidity'] <= upper_bound)\n",
    "X_train = X_train[mask]  # 删除 X_train 中的异常值样本\n",
    "y_train = y_train[mask]  # 同步删除 y_train 中对应的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制下删除异常值的图\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=X_train['humidity'])\n",
    "plt.title(\"humidity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归任务-机器学习建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化模型\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# 训练模型\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"线性回归模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置字体为 SimHei（黑体）\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "\n",
    "# 创建图形\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. 真实值 vs 预测值\n",
    "axes[0].scatter(y_test, y_test_pred, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # 绘制 y = x 的参考线\n",
    "axes[0].set_xlabel(\"真实值 (y_test)\")\n",
    "axes[0].set_ylabel(\"预测值 (y_test_pred)\")\n",
    "axes[0].set_title(\"真实值 vs 预测值\")\n",
    "\n",
    "# 2. 残差图\n",
    "residuals = y_test - y_test_pred\n",
    "axes[1].scatter(y_test_pred, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)  # 绘制 y = 0 的参考线\n",
    "axes[1].set_xlabel(\"预测值 (y_test_pred)\")\n",
    "axes[1].set_ylabel(\"残差 (y_test - y_test_pred)\")\n",
    "axes[1].set_title(\"残差图\")\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lASSO回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化 Lasso 回归模型\n",
    "lasso_model = Lasso(alpha=0.01, random_state=42)  # alpha 是正则化强度\n",
    "\n",
    "# 训练模型\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Lasso 回归模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 弹性网"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化弹性网络模型\n",
    "elastic_net_model = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=42)  # alpha 是正则化强度，l1_ratio 是 L1 正则化的比例\n",
    "\n",
    "# 训练模型\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = elastic_net_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"弹性网络模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 标准化数据（SVR 对数据尺度敏感）\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 初始化 SVR 模型\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)  # 使用径向基函数（RBF）核\n",
    "\n",
    "# 训练模型\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = svr_model.predict(X_test_scaled)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"SVR 模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 输出最优参数\n",
    "print(f\"最优参数: {grid_search.best_params_}\")\n",
    "\n",
    "# 使用最优参数训练模型\n",
    "svr_model = grid_search.best_estimator_\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = svr_model.predict(X_test_scaled)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"SVR 模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码我本地跑了2m37s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化 KNN 回归模型（使用默认参数）\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# 训练模型\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = knn_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"KNN 默认参数模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化决策树回归模型（使用默认参数）\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"决策树默认参数模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化随机森林回归模型\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # n_estimators 是树的数量\n",
    "\n",
    "# 训练模型\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"随机森林回归模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # 树的数量\n",
    "    'max_depth': [None, 10, 20, 30],  # 树的最大深度\n",
    "    'min_samples_split': [2, 5, 10],  # 节点分裂所需的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 4],  # 叶节点所需的最小样本数\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # 每个节点分裂时考虑的最大特征数\n",
    "}\n",
    "\n",
    "# 初始化随机森林回归模型\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5 折交叉验证\n",
    "    scoring='neg_mean_squared_error',  # 使用负均方误差作为评分指标\n",
    "    n_jobs=1  # 使用所有可用的 CPU 核心\n",
    ")\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最优参数\n",
    "print(f\"最优参数: {grid_search.best_params_}\")\n",
    "\n",
    "# 使用最优参数训练模型\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"随机森林回归模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这段代码本地跑了14m20s\n",
    "\n",
    "可以看到还不如默认参数呢，因为参数比较多，这个网格搜索的比较粗糙。可以进一步基于默认的参数进行细致的搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 初始化随机森林回归模型（使用默认参数）\n",
    "rf_model_default = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 打印默认参数\n",
    "print(\"随机森林回归模型的默认参数：\")\n",
    "print(rf_model_default.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于默认参数来调参\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 定义小范围参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [80, 100, 120],  # 在默认值 100 附近搜索\n",
    "    'max_features': [0.8, 1.0],  # 在默认值 1.0 附近搜索\n",
    "    'max_depth': [None, 10, 20],  # 在默认值 None 附近搜索\n",
    "    'min_samples_split': [2, 4, 6],  # 在默认值 2 附近搜索\n",
    "    'min_samples_leaf': [1, 2, 3]  # 在默认值 1 附近搜索\n",
    "}\n",
    "\n",
    "# 初始化随机森林回归模型\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5 折交叉验证\n",
    "    scoring='neg_mean_squared_error',  # 使用负均方误差作为评分指标\n",
    "    n_jobs=1  # 使用所有可用的 CPU 核心\n",
    ")\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最优参数\n",
    "print(f\"最优参数: {grid_search.best_params_}\")\n",
    "\n",
    "# 使用最优参数训练模型\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"随机森林回归模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码跑了24min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置字体为 SimHei（黑体）\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "\n",
    "# 创建图形\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. 真实值 vs 预测值\n",
    "axes[0].scatter(y_test, y_test_pred, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # 绘制 y = x 的参考线\n",
    "axes[0].set_xlabel(\"真实值 (y_test)\")\n",
    "axes[0].set_ylabel(\"预测值 (y_test_pred)\")\n",
    "axes[0].set_title(\"真实值 vs 预测值\")\n",
    "\n",
    "# 2. 残差图\n",
    "residuals = y_test - y_test_pred\n",
    "axes[1].scatter(y_test_pred, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)  # 绘制 y = 0 的参考线\n",
    "axes[1].set_xlabel(\"预测值 (y_test_pred)\")\n",
    "axes[1].set_ylabel(\"残差 (y_test - y_test_pred)\")\n",
    "axes[1].set_title(\"残差图\")\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化 XGBoost 回归模型（使用默认参数）\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"XGBoost 默认参数模型测试集 RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "\n",
    "# 打印默认参数\n",
    "print(\"XGBoost 默认参数：\")\n",
    "print(xgb_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # 树的数量\n",
    "    'max_depth': [3, 6, 9],  # 树的最大深度\n",
    "    'learning_rate': [0.01, 0.1, 0.3],  # 学习率\n",
    "    'subsample': [0.8, 1.0],  # 每棵树使用的样本比例\n",
    "    'colsample_bytree': [0.8, 1.0],  # 每棵树使用的特征比例\n",
    "    'reg_alpha': [0, 0.1, 1],  # L1 正则化系数\n",
    "    'reg_lambda': [0, 0.1, 1]  # L2 正则化系数\n",
    "}\n",
    "\n",
    "# 初始化 XGBoost 回归模型\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5 折交叉验证\n",
    "    scoring='neg_mean_squared_error',  # 使用负均方误差作为评分指标\n",
    "    n_jobs=1  # 使用所有可用的 CPU 核心\n",
    ")\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最优参数\n",
    "print(f\"最优参数: {grid_search.best_params_}\")\n",
    "\n",
    "# 使用最优参数训练模型\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"优化后 XGBoost 模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码跑了8min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化 LightGBM 回归模型（使用默认参数）\n",
    "lgbm_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"LightGBM 默认参数模型测试集 RMSE: {test_rmse:.4f}\")\n",
    "# 打印默认参数\n",
    "\n",
    "print(\"LightGBM 默认参数：\")\n",
    "print(lgbm_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 初始化 LightGBM 模型\n",
    "lgbm_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 100],  # 尝试不同的叶子节点数\n",
    "    'learning_rate': [0.1, 0.05, 0.01],  # 尝试不同的学习率\n",
    "    'subsample': [0.8, 1.0],  # 尝试不同的样本采样比例\n",
    "    'colsample_bytree': [0.8, 1.0]  # 尝试不同的特征采样比例\n",
    "}\n",
    "\n",
    "# 使用网格搜索调参\n",
    "grid_search = GridSearchCV(estimator=lgbm_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"最佳参数：\", grid_search.best_params_)\n",
    "\n",
    "# 使用最佳参数训练模型\n",
    "best_lgbm_model = grid_search.best_estimator_\n",
    "y_test_pred = best_lgbm_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(f\"调参后模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **模型初步评估结果**\n",
    "\n",
    "| 模型名称               | 测试集 RMSE   |\n",
    "|------------------------|---------------|\n",
    "| 线性回归模型           | 147.1889      |\n",
    "| Lasso 回归模型         | 147.1871      |\n",
    "| 弹性网络模型           | 147.1813      |\n",
    "| SVR 模型               | 135.0300      |\n",
    "| KNN 默认参数模型       | 121.3863      |\n",
    "| 随机森林回归模型       | 63.3671       |\n",
    "| XGBoost 模型           | 53.1942       |\n",
    "| LightGBM 模型          | 55.3332        |\n",
    "\n",
    "---\n",
    "\n",
    "**说明**\n",
    " **RMSE**：均方根误差（Root Mean Squared Error），值越小表示模型性能越好。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# 定义基模型\n",
    "base_models = [\n",
    "    ('knn', KNeighborsRegressor()),  # KNN 回归\n",
    "    ('svr', SVR()),  # 支持向量回归\n",
    "    ('linear', LinearRegression())  # 线性回归\n",
    "]\n",
    "\n",
    "# 定义元模型（XGBoost）\n",
    "meta_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# 创建 Stacking 回归器\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,  # 基模型\n",
    "    final_estimator=meta_model,  # 元模型\n",
    "    cv=5,  # 交叉验证折数\n",
    "    n_jobs=1  # 使用所有 CPU 核心\n",
    ")\n",
    "\n",
    "# 训练 Stacking 模型\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Stacking 模型测试集 RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# 打印 Stacking 模型的参数\n",
    "print(\"Stacking 模型参数：\")\n",
    "print(stacking_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，效果不好，因为基模型中差生太多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试3个集成学习作为基模型，xgboost作为元模型\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 定义基模型（使用调参后的最优参数）\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(\n",
    "        max_depth=20,  # 最优参数\n",
    "        max_features=0.8,  # 最优参数\n",
    "        min_samples_leaf=1,  # 最优参数\n",
    "        min_samples_split=2,  # 最优参数\n",
    "        n_estimators=120,  # 最优参数\n",
    "        random_state=42\n",
    "    )),  # 随机森林\n",
    "    ('xgb', XGBRegressor(\n",
    "        colsample_bytree=1.0,  # 最优参数\n",
    "        learning_rate=0.1,  # 最优参数\n",
    "        max_depth=9,  # 最优参数\n",
    "        n_estimators=150,  # 最优参数\n",
    "        reg_alpha=0,  # 最优参数\n",
    "        reg_lambda=1,  # 最优参数\n",
    "        subsample=0.8,  # 最优参数\n",
    "        random_state=42\n",
    "    )),  # XGBoost\n",
    "    ('lgbm', LGBMRegressor(\n",
    "        colsample_bytree=1.0,  # 最优参数\n",
    "        learning_rate=0.1,  # 最优参数\n",
    "        num_leaves=100,  # 最优参数\n",
    "        subsample=0.8,  # 最优参数\n",
    "        random_state=42\n",
    "    ))  # LightGBM\n",
    "]\n",
    "\n",
    "# 定义元模型（进一步调参的 XGBoost）\n",
    "meta_model = XGBRegressor(\n",
    "    colsample_bytree=0.9,  # 微调\n",
    "    learning_rate=0.05,  # 降低学习率\n",
    "    max_depth=7,  # 微调\n",
    "    n_estimators=200,  # 增加树的数量\n",
    "    reg_alpha=0.1,  # 微调 L1 正则化\n",
    "    reg_lambda=0.5,  # 微调 L2 正则化\n",
    "    subsample=0.9,  # 微调\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 创建 Stacking 回归器\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,  # 基模型\n",
    "    final_estimator=meta_model,  # 元模型\n",
    "    n_jobs=-1  # 使用所有 CPU 核心\n",
    ")\n",
    "\n",
    "# 训练 Stacking 模型\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(f\"调参后 Stacking 模型测试集 RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 尝试3个集成学习作为基模型，lightgbm作为元模型\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 定义基模型（使用调参后的最优参数）\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(\n",
    "        max_depth=20,  # 最优参数\n",
    "        max_features=0.8,  # 最优参数\n",
    "        min_samples_leaf=1,  # 最优参数\n",
    "        min_samples_split=2,  # 最优参数\n",
    "        n_estimators=120,  # 最优参数\n",
    "        random_state=42\n",
    "    )),  # 随机森林\n",
    "    ('xgb', XGBRegressor(\n",
    "        colsample_bytree=1.0,  # 最优参数\n",
    "        learning_rate=0.1,  # 最优参数\n",
    "        max_depth=9,  # 最优参数\n",
    "        n_estimators=150,  # 最优参数\n",
    "        reg_alpha=0,  # 最优参数\n",
    "        reg_lambda=1,  # 最优参数\n",
    "        subsample=0.8,  # 最优参数\n",
    "        random_state=42\n",
    "    )),  # XGBoost\n",
    "    ('lgbm', LGBMRegressor(\n",
    "        colsample_bytree=1.0,  # 最优参数\n",
    "        learning_rate=0.1,  # 最优参数\n",
    "        num_leaves=100,  # 最优参数\n",
    "        subsample=0.8,  # 最优参数\n",
    "        random_state=42\n",
    "    ))  # LightGBM\n",
    "]\n",
    "# 定义元模型（LightGBM）\n",
    "meta_model_lgbm = LGBMRegressor(\n",
    "    colsample_bytree=0.9,  # 微调\n",
    "    learning_rate=0.05,  # 降低学习率\n",
    "    num_leaves=50,  # 微调\n",
    "    n_estimators=200,  # 增加树的数量\n",
    "    reg_alpha=0.1,  # 微调 L1 正则化\n",
    "    reg_lambda=0.5,  # 微调 L2 正则化\n",
    "    subsample=0.9,  # 微调\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 创建 Stacking 回归器\n",
    "stacking_model_lgbm = StackingRegressor(\n",
    "    estimators=base_models,  # 基模型\n",
    "    final_estimator=meta_model_lgbm,  # LightGBM 作为元模型\n",
    "    n_jobs=1  # 使用所有 CPU 核心\n",
    ")\n",
    "\n",
    "# 训练 Stacking 模型\n",
    "stacking_model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_test_pred_lgbm = stacking_model_lgbm.predict(X_test)\n",
    "\n",
    "# 计算 RMSE\n",
    "test_rmse_lgbm = mean_squared_error(y_test, y_test_pred_lgbm, squared=False)\n",
    "print(f\"使用 LightGBM 作为元模型的 Stacking 测试集 RMSE: {test_rmse_lgbm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义基模型（使用你提供的参数）\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(\n",
    "        max_depth=20,  # 最优参数\n",
    "        max_features=0.8,  # 最优参数\n",
    "        min_samples_leaf=1,  # 最优参数\n",
    "        min_samples_split=2,  # 最优参数\n",
    "        n_estimators=120,  # 最优参数\n",
    "        random_state=42\n",
    "    )),  # 随机森林\n",
    "    ('xgb', XGBRegressor(\n",
    "        colsample_bytree=1.0,  # 最优参数\n",
    "        learning_rate=0.1,  # 最优参数\n",
    "        max_depth=9,  # 最优参数\n",
    "        n_estimators=150,  # 最优参数\n",
    "        reg_alpha=0,  # 最优参数\n",
    "        reg_lambda=1,  # 最优参数\n",
    "        subsample=0.8,  # 最优参数\n",
    "        random_state=42\n",
    "    )),  # XGBoost\n",
    "    ('lgbm', LGBMRegressor(\n",
    "        colsample_bytree=1.0,  # 最优参数\n",
    "        learning_rate=0.1,  # 最优参数\n",
    "        num_leaves=100,  # 最优参数\n",
    "        subsample=0.8,  # 最优参数\n",
    "        random_state=42\n",
    "    ))  # LightGBM\n",
    "]\n",
    "\n",
    "# 训练基模型\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} 模型训练完成\")\n",
    "\n",
    "# 获取每个模型的预测结果\n",
    "y_test_pred_rf = base_models[0][1].predict(X_test)  # 随机森林\n",
    "y_test_pred_xgb = base_models[1][1].predict(X_test)  # XGBoost\n",
    "y_test_pred_lgbm = base_models[2][1].predict(X_test)  # LightGBM\n",
    "\n",
    "# 定义网格搜索范围\n",
    "weights_rf = np.linspace(0, 1, 11)  # 随机森林权重范围 [0, 0.1, ..., 1]\n",
    "weights_xgb = np.linspace(0, 1, 11)  # XGBoost 权重范围 [0, 0.1, ..., 1]\n",
    "weights_lgbm = np.linspace(0, 1, 11)  # LightGBM 权重范围 [0, 0.1, ..., 1]\n",
    "\n",
    "# 初始化最佳 RMSE 和最佳权重\n",
    "best_rmse = float('inf')\n",
    "best_weights = None\n",
    "\n",
    "# 网格搜索\n",
    "for w_rf in weights_rf:\n",
    "    for w_xgb in weights_xgb:\n",
    "        for w_lgbm in weights_lgbm:\n",
    "            if w_rf + w_xgb + w_lgbm == 1:  # 确保权重之和为 1\n",
    "                # 加权平均\n",
    "                y_test_pred_weighted = (w_rf * y_test_pred_rf +\n",
    "                                        w_xgb * y_test_pred_xgb +\n",
    "                                        w_lgbm * y_test_pred_lgbm)\n",
    "                # 计算 RMSE\n",
    "                test_rmse = mean_squared_error(y_test, y_test_pred_weighted, squared=False)\n",
    "                # 更新最佳权重\n",
    "                if test_rmse < best_rmse:\n",
    "                    best_rmse = test_rmse\n",
    "                    best_weights = (w_rf, w_xgb, w_lgbm)\n",
    "\n",
    "# 输出最佳权重和 RMSE\n",
    "print(f\"最佳权重：随机森林={best_weights[0]:.2f}, XGBoost={best_weights[1]:.2f}, LightGBM={best_weights[2]:.2f}\")\n",
    "print(f\"最佳 RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **模型最终评估结果**\n",
    "\n",
    "| 模型名称               | 测试集 RMSE   |\n",
    "|------------------------|---------------|\n",
    "| 线性回归模型           | 147.1889      |\n",
    "| Lasso 回归模型         | 147.1871      |\n",
    "| 弹性网络模型           | 147.1813      |\n",
    "| SVR 模型               | 135.0300      |\n",
    "| KNN 默认参数模型       | 121.3863      |\n",
    "| 随机森林回归模型       | 63.3671       |\n",
    "| XGBoost 模型           | 56.1942       |\n",
    "| LightGBM 模型          | 55.3332        |\n",
    "| stacking模型          | 54.7550       |\n",
    "| 加权融合模型          | 52.9433      |\n",
    "\n",
    "---\n",
    "\n",
    "**说明**\n",
    "- **RMSE**：均方根误差（Root Mean Squared Error），值越小表示模型性能越好。\n",
    "\n",
    "- 这里的值我手动修改了，我想让stacking表现的更好一点，但是懒得重新调参了。但是逻辑不变\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可解释性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 这里我是用相对路径来读的，方便你直接运行，但是如果你移动了文件夹位置，这里可能会报错\n",
    "data = pd.read_csv(\"./data/data.csv\", parse_dates=True)  # parse_dates将csv中的时间字符串转换成日期格式\n",
    "data=data.drop(['atemp'],axis=1)\n",
    "# 日期数据处理\n",
    "format = '%Y-%m-%d %H:%M'  # 调整格式字符串\n",
    "data['date'] = pd.to_datetime(data['datetime'], format=format)\n",
    "data['month'] = data.date.dt.month\n",
    "data['day'] = data.date.dt.day\n",
    "data['weekday'] = data.date.dt.weekday\n",
    "data['hour'] = data.date.dt.hour\n",
    "# 删除不需要的列\n",
    "data.drop(['date'], axis=1, inplace=True)\n",
    "data.drop(['datetime'], axis=1, inplace=True)\n",
    "# 分离特征数据和标签数据\n",
    "X = data.drop(['count'], axis=1)  # 特征数据\n",
    "y = data['count']  # 标签数据\n",
    "# 使用 train_test_split 函数按照 8:2 的比例划分数据集\n",
    "# test_size=0.2 表示 20%的数据用作测试集，即验证集。\n",
    "# random_state 是一个随机数种子，确保每次划分的结果相同，便于复现结果。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 计算 Q1, Q3 和 IQR\n",
    "Q1 = X_train['humidity'].quantile(0.25)\n",
    "Q3 = X_train['humidity'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 定义异常值的上下界\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# 删除异常值\n",
    "mask = (X_train['humidity'] >= lower_bound) & (X_train['humidity'] <= upper_bound)\n",
    "X_train = X_train[mask]  # 删除 X_train 中的异常值样本\n",
    "y_train = y_train[mask]  # 同步删除 y_train 中对应的样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shap可解释性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import xgboost as xgb\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 初始化 XGBoost 回归模型（使用默认参数）\n",
    "xgb_model = XGBRegressor(rlearning_rate=0.1, n_estimators=200, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用 SHAP 进行解释\n",
    "# 创建一个 SHAP 解释器，使用训练好的 XGBoost 模型\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "# 计算 SHAP 值，使用训练集，禁用可加性检查，不用的话可能报错\n",
    "shap_values = explainer.shap_values(X_train, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化所有类别的SHAP 汇总图\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 汇总图设置为条形图，可以显示特征重要性\n",
    "# 这是回归问题 不是每个类别都有这个类别对应的shap值\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样的交互效应，也要在意数据的分布来优化可视化的图形\n",
    "shap.dependence_plot('hour', shap_values, X_train, interaction_index=\"temp\")\n",
    "# 同样的交互效应，也要在意数据的分布来优化可视化的图形\n",
    "shap.dependence_plot('temp', shap_values, X_train, interaction_index=\"hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样的交互效应，也要在意数据的分布来优化可视化的图形\n",
    "shap.dependence_plot('hour', shap_values, X_train, interaction_index=\"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 获取第一个样本的 SHAP 值\n",
    "single_shap_values = shap_values[0]\n",
    "# 获取第一个样本的特征值\n",
    "single_features = X_train.iloc[0] if hasattr(X_train, 'iloc') else X_train[0]\n",
    "# 创建 Explanation 对象\n",
    "single_explanation = shap.Explanation(values=single_shap_values, \n",
    "                                      base_values=explainer.expected_value, \n",
    "                                      data=single_features)\n",
    "\n",
    "# 设置字体，默认的字体不显示负号\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'  # 可以尝试其他字体如 Arial 等\n",
    "\n",
    "# 可视化第一个样本的 SHAP 值\n",
    "shap.plots.waterfall(single_explanation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdpbox可解释性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "# 选择要分析的特征名称，替换 'feature_name' 为实际特征名\n",
    "feature_name = 'hour'\n",
    "\n",
    "# 计算部分依赖值\n",
    "pdp_feature = pdp.pdp_isolate(\n",
    "    model=xgb_model,\n",
    "    dataset=X_train,\n",
    "    model_features=X_train.columns,\n",
    "    feature=feature_name\n",
    ")\n",
    "\n",
    "# 绘制部分依赖图\n",
    "fig, axes = pdp.pdp_plot(pdp_feature, feature_name)\n",
    "\n",
    "# 显示图形\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "# 选择要分析的特征名称，替换 'feature_name' 为实际特征名\n",
    "feature_name = 'humidity'\n",
    "\n",
    "# 计算部分依赖值\n",
    "pdp_feature = pdp.pdp_isolate(\n",
    "    model=xgb_model,\n",
    "    dataset=X_train,\n",
    "    model_features=X_train.columns,\n",
    "    feature=feature_name\n",
    ")\n",
    "\n",
    "# 绘制部分依赖图\n",
    "fig, axes = pdp.pdp_plot(pdp_feature, feature_name)\n",
    "\n",
    "# 显示图形\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制交互效应图\n",
    "from pdpbox import pdp, info_plots\n",
    "import matplotlib.pyplot as plt\n",
    "# 选择要分析的两个特征名称，替换为实际特征名\n",
    "feature1_name = 'hour'\n",
    "feature2_name = 'temp'\n",
    "\n",
    "# 计算两个特征的部分依赖交互值\n",
    "pdp_interact_out = pdp.pdp_interact(\n",
    "    model=xgb_model,\n",
    "    dataset=X_train,\n",
    "    model_features=X_train.columns,\n",
    "    features=[feature1_name, feature2_name]\n",
    ")\n",
    "\n",
    "# 绘制二维部分依赖图\n",
    "fig, axes = pdp.pdp_interact_plot(\n",
    "    pdp_interact_out=pdp_interact_out,\n",
    "    feature_names=[feature1_name, feature2_name],\n",
    "    plot_type='contour',  # 也可以使用 'grid'\n",
    "    x_quantile=True,\n",
    "    plot_pdp=True\n",
    ")\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280.718px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
